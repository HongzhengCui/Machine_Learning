{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate linear regression\n",
    "\n",
    "\n",
    "In this notebook, we will make use of the multivariate linear regression to predict the price of houses. We will use the Boston house price dataset available at https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html for our purpose. The dataset includes many attributes per house and its price. Some examples of the attributes are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "mlr_data = np.load('multivariate_linear_regression_dataset.npz')\n",
    "X_train = mlr_data['X']\n",
    "y_train = mlr_data['y']\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution of the linear regression can be written as \n",
    "\\begin{align}\n",
    "\\mathbf{w} = \\mathbf{X}^{+}\\mathbf{y}\\;,\n",
    "\\end{align}\n",
    "where $\\mathbf{X}^{+}$ is the pseudoinverse of $\\mathbf{X}$. \n",
    "Recall that $\\mathbf{X}$ is a matrix where each row is one sample and $\\boldsymbol{y}$\n",
    "is a vector of target values.\n",
    "\n",
    "\n",
    "\n",
    "Using the Numpy pseudoinverse function, we will define a \n",
    "function to fit a linear regression model to our data. \n",
    "If we need to add a bias, we can simply augment our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_LinearRegression(X, y, bias=True):\n",
    "\n",
    "    # Insert constant ones for bias weights\n",
    "    if (bias):\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "\n",
    "    w = np.linalg.pinv(X).dot(y)\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define another function for prediction $\\hat{y} = \\mathbf{w}^\\top\\mathbf{x}$. Our function below will also compute the mean square error defined as\n",
    "\\begin{align}\n",
    "\\mathcal{L}_{SE} = \\frac{1}{m} \\sum_{i=1}^m \\|y_i - \\hat{y}_i\\|^2\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_LinearRegression(w, X, y, bias=True):\n",
    "\n",
    "    # Insert constant ones for bias weights\n",
    "    \n",
    "    if (bias):\n",
    "        b_star = w[0]  #recall that with bias, we put the bias into teh first element of w (index = 0) \n",
    "        w_star = w[1:] \n",
    "        y_hat = X.dot(w_star) + b_star\n",
    "    else:\n",
    "        y_hat = X.dot(w)\n",
    "            \n",
    "    \n",
    "    mse = np.mean(np.square(y-y_hat))\n",
    "    return y_hat, mse    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first fit a linear model without bias and evaluate it as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = fit_LinearRegression(X_train, y_train, bias=False)\n",
    "y_hat1, mse1 = predict_LinearRegression(w1,X_train, y_train, bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then fit a linear model with bias and evaluate it as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Error without bias: 24.166099330126492\n",
      "Regression Error with bias: 21.894831181729206\n"
     ]
    }
   ],
   "source": [
    "w2 = fit_LinearRegression(X_train, y_train, bias=True)\n",
    "y_hat2, mse2 = predict_LinearRegression(w2,X_train, y_train, bias=True)\n",
    "print(\"Regression Error without bias:\", mse1)\n",
    "print(\"Regression Error with bias:\", mse2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model with bias has a lower error. Let's check some of the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y   without bias  with bias\n",
      "0  24.0    29.098264   30.003843\n",
      "1  21.6    24.502275   25.025562\n",
      "2  34.7    31.227426   30.567597\n",
      "3  33.4    29.707104   28.607036\n",
      "4  36.2    29.564796   27.943524\n"
     ]
    }
   ],
   "source": [
    "df = pandas.DataFrame({\"y\": y_train[:5], \"without bias\": y_hat1[:5], \"with bias\": y_hat2[:5]})\n",
    "pandas.set_option('colheader_justify', 'center')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seems that for the very first five samples, the model without bias works better. Let's check out some other samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y   without bias  with bias\n",
      "0  28.7    29.098264   25.256284\n",
      "1  22.9    24.502275   23.001808\n",
      "2  27.1    31.227426   19.535988\n",
      "3  16.5    29.707104   11.523637\n",
      "4  18.9    29.564796   18.920262\n"
     ]
    }
   ],
   "source": [
    "df = pandas.DataFrame({\"y\": y_train[5:10], \"without bias\": y_hat1[:5], \"with bias\": y_hat2[5:10]})\n",
    "pandas.set_option('colheader_justify', 'center')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, look, in some cases the model with bias does a much better job. \n",
    "Now, let us have some fun. Let us add some non-linear features to our model. The idea folows the concept of polynomial regression, check this [Wikipedia page](https://en.wikipedia.org/wiki/Polynomial_regression) for a brief inroduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Error with with poly-2 features: 14.24702704237634\n"
     ]
    }
   ],
   "source": [
    "X_quad = np.concatenate((X_train, X_train**2),axis=1)\n",
    "w3 = fit_LinearRegression(X_quad, y_train, bias=True)\n",
    "y_hat3, mse3 = predict_LinearRegression(w3, X_quad, y_train, bias=True)\n",
    "print(\"Regression Error with with poly-2 features:\", mse3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y   linear features  poly-2 features\n",
      "0  24.0     30.003843        28.340697   \n",
      "1  21.6     25.025562        23.296078   \n",
      "2  34.7     30.567597        31.926581   \n",
      "3  33.4     28.607036        32.024942   \n",
      "4  36.2     27.943524        30.071343   \n"
     ]
    }
   ],
   "source": [
    "df = pandas.DataFrame({\"y\": y_train[:5], \"linear features\": y_hat2[:5], \"poly-2 features\": y_hat3[:5]})\n",
    "pandas.set_option('colheader_justify', 'center')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we continue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Error with poly-3 features: 13.060641842807836\n"
     ]
    }
   ],
   "source": [
    "X_cube = np.concatenate((X_train, X_train**2, X_train**3),axis=1)\n",
    "w4 = fit_LinearRegression(X_cube, y_train, bias=True)\n",
    "y_hat4, mse4 = predict_LinearRegression(w4, X_cube, y_train, bias=True)\n",
    "print(\"Regression Error with poly-3 features:\", mse4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y   linear features  poly-3 features\n",
      "0  24.0     30.003843        28.340697   \n",
      "1  21.6     25.025562        23.296078   \n",
      "2  34.7     30.567597        31.926581   \n",
      "3  33.4     28.607036        32.024942   \n",
      "4  36.2     27.943524        30.071343   \n"
     ]
    }
   ],
   "source": [
    "df = pandas.DataFrame({\"y\": y_train[:5], \"linear features\": y_hat2[:5], \"poly-3 features\": y_hat3[:5]})\n",
    "pandas.set_option('colheader_justify', 'center')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we have to realize that increasing polynomial dimensions may cause **overfitting**, as shown in the image below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://drek4537l1klr.cloudfront.net/serrano/Figures/4-3.png\" width=\"800\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://drek4537l1klr.cloudfront.net/serrano/Figures/4-3.png', width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
